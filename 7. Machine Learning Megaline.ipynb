{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1 Cargar los datos](#1)\n",
    "* [2 Separar los datos en dos conjuntos](#2)\n",
    "* [3 Evaluacion de los modelos](#3)\n",
    "* [4 Validacion del modelo](#4)\n",
    "* [5 Conclusion](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos las librerías\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el dataframe a usar\n",
    "\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizamos el dataframe\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# observamos las generalidades del dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se procede a trabajar ya que no observamos ninguna anomalía en los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar los datos en dos conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.20, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos\n",
    "\n",
    "features_train = df_train.drop(['is_ultra'], axis = 1)\n",
    "\n",
    "features_test = df_test.drop(['is_ultra'], axis = 1)\n",
    "\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acá, procederemos a evaluar los tres modelos: de arbol de decision, de bosque aleatorio y de regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el modelo con el arbol de decision con datos de entrenamiento\n",
    "\n",
    "#best_model = None\n",
    "#best_result = 0\n",
    "\n",
    "#for depth in range(1, 6):\n",
    "   # model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "   # model.fit(features_train, target_train)\n",
    "   # predictions = model.predict(features_train)\n",
    "   # result = accuracy_score(target_train, predictions)\n",
    "    \n",
    "   # if result > best_result:\n",
    "    #    best_model = model\n",
    "    #    best_result = result\n",
    "    \n",
    "# print('EXACTITUD DEL MEJOR MODELO EN EL ENTRENAMIENTO:', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXACTITUD DEL MEJOR MODELO EN EL ENTRENAMIENTO CON DATOS DE PRUEBA: 0.7853810264385692\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo con el arbol de decision con datos de prueba \n",
    "\n",
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_test)\n",
    "    result = accuracy_score(target_test, predictions)\n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "    \n",
    "print('EXACTITUD DEL MEJOR MODELO EN EL ENTRENAMIENTO CON DATOS DE PRUEBA:', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se puede notar que hay un sobreajuste en la evaluación del 3%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION DEL MEJOR MODEL DEL ENTRENAMIENTO: (n_estimators = 9): 0.9782185919875535\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo de bosque con datos de entrenamiento\n",
    "\n",
    "#best_score = 0 \n",
    "#best_est = 0\n",
    "\n",
    "#for est in range(1, 11):\n",
    "#    model = RandomForestClassifier(random_state = 12345, n_estimators = est)\n",
    "#    model.fit(features_train, target_train)\n",
    "#    score = model.score(features_train, target_train)\n",
    "#    if score > best_score:\n",
    "#        best_score = score\n",
    "#        best_est = est\n",
    "        \n",
    "#print(\"PRECISION DEL MEJOR MODEL DEL ENTRENAMIENTO: (n_estimators = {}): {}\".format(best_est, best_score))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION DEL MEJOR MODEL DEL ENTRENAMIENTO CON LOS DATOS DE PRUEBA: (n_estimators = 4): 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo de bosque con datos de prueba\n",
    "\n",
    "best_score = 0 \n",
    "best_est = 0\n",
    "\n",
    "for est in range(1, 11):\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_test, target_test)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "        \n",
    "print(\"PRECISION DEL MEJOR MODEL DEL ENTRENAMIENTO CON LOS DATOS DE PRUEBA: (n_estimators = {}): {}\".format(best_est, best_score))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esta evaluación muestra un sobreajuste del 20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION DEL MODELO DE REGRESION LOGISTICA EN EL ENTRENAMIENTO: 0.7016725009723843\n",
      "PRECISION DEL MODELO DE REGRESION LOGISTICA EN LA PRUEBA:  0.702954898911353\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion del modelo de regresion logistica\n",
    "\n",
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "score_train = model.score(features_train, target_train)\n",
    "score_test = model.score(features_test, target_test)\n",
    "\n",
    "print('PRECISION DEL MODELO DE REGRESION LOGISTICA EN EL ENTRENAMIENTO:', score_train)\n",
    "print('PRECISION DEL MODELO DE REGRESION LOGISTICA EN LA PRUEBA: ', score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se pudo observar que no presenta sobreajuste determinante además que se que ambos modelos se muestran por debajo de 0.75**\n",
    "\n",
    "**Se determinó que el mejor modelo que mejor resultados nos da es el del arbol de decision, ya que supera los 0.75**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADO DE ASEVERACION DEL ESTUDIO DEL CONJUNTO DE ENTRENAMIENTO: 0.6931155192532089\n",
      "RESULTADO DE ASEVERACION DEL ESTUDIO DEL CONJUNTO DE PRUEBA: 0.6951788491446346\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion del modelo de cordura (Model Sanity Check)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "model = DummyClassifier(random_state = 42)\n",
    "model.fit(features_test, target_test)\n",
    "predictions = dummy_model.predict(features_test)\n",
    "score_train= model.score(features_train, target_train)\n",
    "score_test = model.score(features_test, target_test)\n",
    "\n",
    "\n",
    "print('RESULTADO DE ASEVERACION DEL ESTUDIO DEL CONJUNTO DE ENTRENAMIENTO:', score_train)\n",
    "print('RESULTADO DE ASEVERACION DEL ESTUDIO DEL CONJUNTO DE PRUEBA:', score_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procedio a colocar la evaluacion del modelo de cordura, que es las que nos indica si el resultado de un calculo o una aseveración puede ser posible. Se importo la libreria correspondiente y los resultados fueron por debajo del 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos los datos en conjuntos de entrenamiento y validación\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size = 0.25, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos \n",
    "\n",
    "features_train = df_train.drop(['is_ultra'], axis = 1)\n",
    "\n",
    "features_valid = df_valid.drop(['is_ultra'], axis = 1)\n",
    "\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "target_valid = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXACTITUD DEL MEJOR MODELO CON EL CONJUNTO DE VALIDACION: 0.7885572139303483\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo con el arbol de decision con datos de validación\n",
    "\n",
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "    \n",
    "print('EXACTITUD DEL MEJOR MODELO CON EL CONJUNTO DE VALIDACION:', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h2> Comentarios del estudiante</h2>\n",
    "Al validar, podemos notar que la exactitud es de 0.7885 mientras que anteriormente habiamos obtenido 0.7853, una diferencia muy minima.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el apartado de evaluacion de modelos, se puede observar que el modelo que da mejores resultados es el del árbol de decisión. ¿Por qué? Debido a que muestra una exactitud mayor a 0.75 (muestra 0.7885). \n",
    "\n",
    "* Los otros dos modelos, el del bosque aleatorio y de regresión logística mostraron datos que no se adecuan a lo que se busca, como una diferencia entre prueba y entrenamiento superior al 20% y unos resultados subajustados, por debajo de 0.75, respectivamente.\n",
    "\n",
    "* Se recomienda utilizar el modelo del arbol de decisión, ya que los datos de prueba son similares a los datos de validación, la diferencia es muy minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h2> Comentarios del revisor </h2>\n",
    "\n",
    "    \n",
    "Parece que hay código duplicados, con celdas correctas y otras no. Revisa las celdas que vas a dejar al final, recuerda que adicionalmente el conjunto debe dividirse en datos de entrenamiento, uno de validación y uno de prueba.Y si tienes la oportunidad implementar el modelo de cordura, seguro no tendrás problemas con las correcciones. Saludos!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> Comentarios del revisor V2</h2>\n",
    "\n",
    "Muy buen trabajo con todas las correcciones Douglas! Felicitaciones por aprobar todos los puntos del proyecto!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
